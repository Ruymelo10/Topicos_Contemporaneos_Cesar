{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9rVMNAR4Ttea","executionInfo":{"status":"ok","timestamp":1724115814496,"user_tz":180,"elapsed":9060,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import math"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"r6OK5mKeTtea","executionInfo":{"status":"ok","timestamp":1724115814497,"user_tz":180,"elapsed":12,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}}},"outputs":[],"source":["d_model = 512\n","num_heads = 8\n","d_ff = 2048\n","batch_size = 32"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RezI05CbTteb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724115814497,"user_tz":180,"elapsed":4,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}},"outputId":"17bd9c31-8858-451a-e964-3f2c7a8df6dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([50, 32, 512])\n"]}],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super().__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return x + self.pe[:x.size(0), :]\n","\n","# Exemplo\n","max_len = 100\n","pos_encoding = PositionalEncoding(d_model, max_len)\n","\n","# (sequence_length, batch_size, d_model)\n","input_tensor = torch.randn(50, batch_size, d_model)\n","output_tensor = pos_encoding(input_tensor)\n","\n","print(output_tensor.shape)  # Output shape: (sequence_length, batch_size, d_model)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"lWF5GLTKTteb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724115815001,"user_tz":180,"elapsed":506,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}},"outputId":"a1c5a767-bcb9-4ed1-cd82-97b08f36c580"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        # Verifica se o número de dimensões do modelo é divisível pelo número de cabeças\n","        assert d_model % num_heads == 0\n","\n","        # Número de dimensões por cabeça\n","        self.d_k = d_model // num_heads\n","        self.num_heads = num_heads\n","\n","        # Inicializa as camadas lineares para Q, K e V\n","        self.W_q = nn.Linear(d_model, d_model)\n","        self.W_k = nn.Linear(d_model, d_model)\n","        self.W_v = nn.Linear(d_model, d_model)\n","        self.W_o = nn.Linear(d_model, d_model)\n","\n","    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n","        # Calcula os scores fazendo o produto escalar entre Q e K e dividindo pela raiz quadrada de d_k\n","        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n","\n","        # Se a máscara for fornecida, aplica a máscara para os scores\n","        if mask is not None:\n","            scores = scores.masked_fill(mask == 0, float('-inf'))\n","\n","        # Calcula a softmax nos scores\n","        attention = torch.softmax(scores                    , dim=-1)\n","\n","        # Multiplica a matriz de atenção pelo valor V\n","        output = torch.matmul(attention, V)\n","        return output\n","\n","    def split_heads(self, x):\n","        # Divide a última dimensão em (num_heads, d_k)\n","        N, seq_len, d_model = x.size()\n","        return x.view(N, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n","\n","    def combine_heads(self, x):\n","        # Inverte a operação de split_heads\n","        N, _, seq_len, _ = x.size()\n","        return x.transpose(1, 2).contiguous().view(N, seq_len, self.num_heads * self.d_k)\n","\n","    def forward(self, query, key, value, mask=None):\n","        N = query.shape[0]\n","        query_len, key_len, value_len = query.shape[1], key.shape[1], value.shape[1]\n","\n","        # Passa os valores de Q, K e V pela camada linear\n","        Q = self.split_heads(self.W_q(query))\n","        K = self.split_heads(self.W_k(key))\n","        V = self.split_heads(self.W_v(value))\n","\n","        # Calcula a atenção\n","        attention = self.scaled_dot_product_attention(Q, K, V, mask)\n","\n","        # Combina as cabeças e aplica a camada linear final\n","        output = self.combine_heads(attention)\n","        output = self.W_o(output)\n","        return output\n","\n","\n","multi_head_attn = MultiHeadAttention(d_model, num_heads)\n","\n","# (batch_size, sequence_length, d_model)\n","query = torch.randn(batch_size, 50, d_model)\n","key = torch.randn(batch_size, 50, d_model)\n","value = torch.randn(batch_size, 50, d_model)\n","\n","output = multi_head_attn(query, key, value)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"j9jo07gETtec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724115815896,"user_tz":180,"elapsed":897,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}},"outputId":"b1a24680-99a1-49c4-b61e-cde196881db9"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class FeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff):\n","        super().__init__()\n","        self.fc1 = nn.Linear(d_model, d_ff)\n","        self.fc2 = nn.Linear(d_ff, d_model)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        return self.fc2(self.relu(self.fc1(x)))\n","\n","\n","d_model = 512\n","d_ff = 2048\n","ffn = FeedForward(d_model, d_ff)\n","\n","# (batch_size, sequence_length, d_model)\n","input_tensor = torch.randn(32, 50, d_model)\n","\n","output = ffn(input_tensor)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"vXQqe0k3Ttec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724115817404,"user_tz":180,"elapsed":1511,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}},"outputId":"920bd5b6-38e7-4aa8-ec72-edf4b87b9540"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n","        super().__init__()\n","        self.attention = MultiHeadAttention(d_model, num_heads)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.ffn = FeedForward(d_model, d_ff)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        attn_output = self.attention(x, x, x, mask)\n","        x = self.norm1(x + self.dropout(attn_output))\n","        ffn_output = self.ffn(x)\n","        x = self.norm2(x + self.dropout(ffn_output))\n","        return x\n","\n","\n","encoder_layer = EncoderLayer(d_model, num_heads, d_ff)\n","\n","# (batch_size, sequence_length, d_model)\n","input_tensor = torch.randn(32, 50, d_model)\n","\n","output = encoder_layer(input_tensor)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"x3dGLDcVTtec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724115822027,"user_tz":180,"elapsed":4625,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}},"outputId":"b7d918ec-0b7a-4e8b-8959-20dd65a09065"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 100, 512])\n"]}],"source":["class Encoder(nn.Module):\n","    def __init__(self, src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout=0.1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(src_vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","        x = self.dropout(x)\n","\n","        # Passa a entrada por cada camada do encoder\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","\n","        return x\n","\n","\n","src_vocab_size = 1000\n","num_layers = 6\n","max_len = 100\n","\n","encoder = Encoder(src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len)\n","\n","# (batch_size, sequence_length)\n","input_seq = torch.randint(0, src_vocab_size, (32, 100))\n","\n","output = encoder(input_seq)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Uwzye8SiTtec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724115822531,"user_tz":180,"elapsed":514,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}},"outputId":"87658a48-c1a1-4cb5-e1b1-b05a8de3ccca"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n","        super().__init__()\n","        self.self_attention = MultiHeadAttention(d_model, num_heads)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.cross_attention = MultiHeadAttention(d_model, num_heads)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.ffn = FeedForward(d_model, d_ff)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_out, src_mask=None, trg_mask=None):\n","        # Self-attention na sequência de destino\n","        self_attn_output = self.self_attention(x, x, x, trg_mask)\n","        x = self.norm1(x + self.dropout(self_attn_output))\n","\n","        # Cross-attention entre a saída do self-attention e a saída do encoder\n","        cross_attn_output = self.cross_attention(x, enc_out, enc_out, src_mask)\n","        x = self.norm2(x + self.dropout(cross_attn_output))\n","\n","        # Feed-forward\n","        ffn_output = self.ffn(x)\n","        x = self.norm3(x + self.dropout(ffn_output))\n","\n","        return x\n","\n","\n","decoder_layer = DecoderLayer(d_model, num_heads, d_ff)\n","\n","# (batch_size, sequence_length, d_model)\n","input_tensor = torch.randn(32, 50, d_model)\n","enc_out = torch.randn(32, 50, d_model)\n","\n","output = decoder_layer(input_tensor, enc_out)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"cZaBg8eCTtec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724115827900,"user_tz":180,"elapsed":5371,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}},"outputId":"cf76dd2a-ea5b-4a0d-a8e1-5ab5a88a9ba1"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 100, 1000])\n"]}],"source":["# Decoder\n","class Decoder(nn.Module):\n","    def __init__(self, trg_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout=0.1):\n","        super(Decoder, self).__init__()\n","        self.embedding = nn.Embedding(trg_vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_out, src_mask=None, trg_mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","        x = self.dropout(x)\n","\n","        # Passa a entrada por cada camada do decoder\n","        for layer in self.layers:\n","            x = layer(x, enc_out, src_mask, trg_mask)\n","\n","        out = self.fc_out(x)\n","        return out\n","\n","\n","trg_vocab_size = 1000\n","num_layers = 6\n","max_len = 100\n","\n","decoder = Decoder(trg_vocab_size, d_model, num_heads, num_layers, d_ff, max_len)\n","\n","# (batch_size, sequence_length)\n","trg_seq = torch.randint(0, trg_vocab_size, (32, 100))\n","enc_out = torch.randn(32, 100, d_model)\n","\n","output = decoder(trg_seq, enc_out)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, trg_vocab_size)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"zg4sA6RDTtec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724115837805,"user_tz":180,"elapsed":9914,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}},"outputId":"86ea7d7c-e8fd-4c2d-e461-94a4148470cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 100, 1000])\n"]}],"source":["# Transformer Completo\n","class Transformer(nn.Module):\n","    def __init__(self, src_vocab_size, trg_vocab_size, d_model, num_heads, num_encoder_layers, num_decoder_layers, d_ff, max_len, dropout=0.1):\n","        super().__init__()\n","        self.encoder = Encoder(src_vocab_size, d_model, num_heads, num_encoder_layers, d_ff, max_len, dropout)\n","        self.decoder = Decoder(trg_vocab_size, d_model, num_heads, num_decoder_layers, d_ff, max_len, dropout)\n","\n","    def generate_mask(self, src, trg):\n","        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n","        trg_mask = (trg != 0).unsqueeze(1).unsqueeze(3)\n","        seq_length = trg.size(1)\n","        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n","        trg_mask = trg_mask & nopeak_mask\n","        return src_mask, trg_mask\n","\n","    def forward(self, src, trg, src_mask=None, trg_mask=None):\n","        src_mask, trg_mask = self.generate_mask(src, trg)\n","        enc_out = self.encoder(src, src_mask)\n","        out = self.decoder(trg, enc_out, src_mask, trg_mask)\n","        return out\n","\n","\n","src_vocab_size = 1000\n","trg_vocab_size = 1000\n","d_model = 512\n","num_heads = 8\n","num_encoder_layers = 6\n","num_decoder_layers = 6\n","d_ff = 2048\n","max_len = 100\n","\n","transformer = Transformer(src_vocab_size, trg_vocab_size, d_model, num_heads, num_encoder_layers, num_decoder_layers, d_ff, max_len)\n","\n","# (batch_size, sequence_length)\n","src_seq = torch.randint(0, src_vocab_size, (batch_size, 100))\n","trg_seq = torch.randint(0, trg_vocab_size, (batch_size, 100))\n","\n","output = transformer(src_seq, trg_seq)\n","\n","print(output.shape)  # Output shape: (batch_size, target_sequence_length, trg_vocab_size)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"uY5dj0PMTtec","executionInfo":{"status":"ok","timestamp":1724115837805,"user_tz":180,"elapsed":6,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}}},"outputs":[],"source":["# Gerando as máscaras de forma separada\n","\n","def create_padding_mask(seq):\n","    return (seq != 0).unsqueeze(1).unsqueeze(2).type(torch.uint8)  # Cria uma máscara para posições de preenchimento\n","\n","def create_look_ahead_mask(size):\n","    mask = (1 - torch.triu(torch.ones(size, size), diagonal=1)).type(torch.uint8)\n","    return mask  # Cria uma máscara triangular para impedir a atenção em tokens futuros"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Iaj45GjfTted","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724115837805,"user_tz":180,"elapsed":5,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}},"outputId":"02e1aa2f-a8c0-4179-dcab-fbc694f35559"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[1, 1, 0, 1, 0]]]], dtype=torch.uint8)\n"]}],"source":["seq = torch.tensor([[1, 2, 0, 4, 0]])\n","padding_mask = create_padding_mask(seq)\n","print(padding_mask)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"xomkH3cKTted","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724115837805,"user_tz":180,"elapsed":5,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}},"outputId":"fc8771c1-844e-4362-cf28-1dc47ec22d18"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 0, 0, 0, 0],\n","        [1, 1, 0, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1]], dtype=torch.uint8)\n"]}],"source":["look_ahead_mask = create_look_ahead_mask(5)\n","print(look_ahead_mask)"]},{"cell_type":"markdown","metadata":{"id":"cIm0sgyMTted"},"source":["## Exercícios"]},{"cell_type":"markdown","metadata":{"id":"gO07UvAWTted"},"source":["### Exercício 1\n","Implemente um módulo que utilize apenas o módulo Encoder para a classificação de texto em `num_classes` classes. Para a obtenção do vetor de embedding de toda a sequência que será enviado para a cabeça de classificação, faça um pooling de média através da dimensão de sequência."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"C98vVNKgTted","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724119563099,"user_tz":180,"elapsed":4086,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}},"outputId":"c1029c14-1f44-42bc-a488-97fa097ea2a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 5])\n"]}],"source":["class TextClassifier(nn.Module):\n","    def __init__(self, src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, num_classes, dropout=0.1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(src_vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.fc = nn.Linear(d_model, num_classes)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","        x = self.dropout(x)\n","\n","        # Passa a entrada por cada camada do encoder\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","        x = x.mean(dim=1)\n","        out = self.fc(x)\n","\n","        return out\n","\n","\n","\n","src_vocab_size = 1000\n","num_layers = 6\n","max_len = 100\n","\n","classifier = TextClassifier(src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, num_classes=5)\n","\n","# (batch_size, sequence_length)\n","input_seq = torch.randint(0, src_vocab_size, (32, 100))\n","\n","output = classifier(input_seq)\n","\n","print(output.shape)"]},{"cell_type":"markdown","metadata":{"id":"cQaB0WwtTted"},"source":["### Exercício 2\n","Vamos implementar um modelo baseado em stack de decoders. Uma vez que não é necessário cross-attention, pois não há encoders, utilize o módulo `EncoderLayer`. O tamanho do vocabulário deverá ser de 50257, o tamanho dos embeddings de 768, 12 cabeças de atenção, 12 camadas, dimensão da camada feedforward de 3072 e tamanho máximo de sequência 1024. Em seguida, teste com valores aleatórios simulando uma sequência de tokens."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"31Z2ixoPTted","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724119917899,"user_tz":180,"elapsed":15136,"user":{"displayName":"RUY OVIDIO PERRELLI DE MELO","userId":"11031392736059221395"}},"outputId":"ef7add24-07f1-4018-bb8e-38e6a8277c0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50257])\n"]}],"source":["class TextGenerator(nn.Module):\n","    def __init__(self, src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout=0.1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(src_vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.fc = nn.Linear(d_model, src_vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","        x = self.dropout(x)\n","\n","        # Passa a entrada por cada camada do encoder\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","        x = x.mean(dim=1)\n","        out = self.fc(x)\n","\n","        return out\n","\n","\n","generator = TextGenerator(src_vocab_size=50257, d_model=768, num_heads=12, num_layers=12, d_ff=3072, max_len=1024)\n","\n","# (batch_size, sequence_length)\n","input_seq = torch.randint(0, src_vocab_size, (32, 100))\n","\n","output = generator(input_seq)\n","\n","print(output.shape)"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[{"file_id":"https://github.com/silvaan/topicos_contemporaneos/blob/main/Part%202%20-%20LLMs/04%20-%20Transformers.ipynb","timestamp":1724115774497}]}},"nbformat":4,"nbformat_minor":0}